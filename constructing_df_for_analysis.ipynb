{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2w/pb1tg6913llbt6y2rwws4nb00000gn/T/ipykernel_15554/633978790.py:1: DtypeWarning: Columns (348,350,352,582,583,584,585) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('/Users/elizavetakuznecenkova/Library/CloudStorage/OneDrive-Personal/Документы/ВШЭ/Курсач/dataset.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/elizavetakuznecenkova/Library/CloudStorage/OneDrive-Personal/Документы/ВШЭ/Курсач/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>version</th>\n",
       "      <th>doi</th>\n",
       "      <th>A_WAVE</th>\n",
       "      <th>A_YEAR</th>\n",
       "      <th>A_STUDY</th>\n",
       "      <th>B_COUNTRY</th>\n",
       "      <th>B_COUNTRY_ALPHA</th>\n",
       "      <th>C_COW_NUM</th>\n",
       "      <th>...</th>\n",
       "      <th>WVS_Polmistrust_PartyVoter</th>\n",
       "      <th>WVS_LR_MedianVoter</th>\n",
       "      <th>WVS_LibCon_MedianVoter</th>\n",
       "      <th>v2psbars</th>\n",
       "      <th>v2psorgs</th>\n",
       "      <th>v2psprbrch</th>\n",
       "      <th>v2psprlnks</th>\n",
       "      <th>v2psplats</th>\n",
       "      <th>v2xnp_client</th>\n",
       "      <th>v2xps_party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6-0-0 (2024-04-30)</td>\n",
       "      <td>doi.org/10.14281/18241.24</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>AND</td>\n",
       "      <td>232</td>\n",
       "      <td>...</td>\n",
       "      <td>62.434211</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6-0-0 (2024-04-30)</td>\n",
       "      <td>doi.org/10.14281/18241.24</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>AND</td>\n",
       "      <td>232</td>\n",
       "      <td>...</td>\n",
       "      <td>62.434211</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6-0-0 (2024-04-30)</td>\n",
       "      <td>doi.org/10.14281/18241.24</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>AND</td>\n",
       "      <td>232</td>\n",
       "      <td>...</td>\n",
       "      <td>62.434211</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6-0-0 (2024-04-30)</td>\n",
       "      <td>doi.org/10.14281/18241.24</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>AND</td>\n",
       "      <td>232</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6-0-0 (2024-04-30)</td>\n",
       "      <td>doi.org/10.14281/18241.24</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>AND</td>\n",
       "      <td>232</td>\n",
       "      <td>...</td>\n",
       "      <td>66.964286</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 615 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0             version                        doi  \\\n",
       "0             0           0  6-0-0 (2024-04-30)  doi.org/10.14281/18241.24   \n",
       "1             1           1  6-0-0 (2024-04-30)  doi.org/10.14281/18241.24   \n",
       "2             2           2  6-0-0 (2024-04-30)  doi.org/10.14281/18241.24   \n",
       "3             3           3  6-0-0 (2024-04-30)  doi.org/10.14281/18241.24   \n",
       "4             4           4  6-0-0 (2024-04-30)  doi.org/10.14281/18241.24   \n",
       "\n",
       "   A_WAVE  A_YEAR  A_STUDY  B_COUNTRY B_COUNTRY_ALPHA  C_COW_NUM  ...  \\\n",
       "0       7    2018        2         20             AND        232  ...   \n",
       "1       7    2018        2         20             AND        232  ...   \n",
       "2       7    2018        2         20             AND        232  ...   \n",
       "3       7    2018        2         20             AND        232  ...   \n",
       "4       7    2018        2         20             AND        232  ...   \n",
       "\n",
       "  WVS_Polmistrust_PartyVoter  WVS_LR_MedianVoter  WVS_LibCon_MedianVoter  \\\n",
       "0                  62.434211              -999.0                  -999.0   \n",
       "1                  62.434211              -999.0                  -999.0   \n",
       "2                  62.434211              -999.0                  -999.0   \n",
       "3                        NaN                 NaN                     NaN   \n",
       "4                  66.964286              -999.0                  -999.0   \n",
       "\n",
       "   v2psbars  v2psorgs  v2psprbrch  v2psprlnks  v2psplats  v2xnp_client  \\\n",
       "0    -999.0    -999.0      -999.0      -999.0     -999.0        -999.0   \n",
       "1    -999.0    -999.0      -999.0      -999.0     -999.0        -999.0   \n",
       "2    -999.0    -999.0      -999.0      -999.0     -999.0        -999.0   \n",
       "3       NaN       NaN         NaN         NaN        NaN           NaN   \n",
       "4    -999.0    -999.0      -999.0      -999.0     -999.0        -999.0   \n",
       "\n",
       "   v2xps_party  \n",
       "0       -999.0  \n",
       "1       -999.0  \n",
       "2       -999.0  \n",
       "3          NaN  \n",
       "4       -999.0  \n",
       "\n",
       "[5 rows x 615 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97220/97220 [00:01<00:00, 56791.09it/s] \n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(df))):\n",
    "    if df.loc[i, 'B_COUNTRY_ALPHA'] == 'MAR':\n",
    "        df.loc[i, 'B_COUNTRY_ALPHA'] = 'MOR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = df.columns.to_list()\n",
    "c[c.index('B_COUNTRY_ALPHA')] = 'country'\n",
    "df.columns = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[(df['country'] == 'AND') | (df['country'] == 'ARG') |\n",
    "         (df['country'] == 'ARM') | (df['country'] == 'BRA') | (df['country'] == 'CAN')]\n",
    "\n",
    "df2 = df[(df['country'] == 'CHN') | (df['country'] == 'COL') |\n",
    "         (df['country'] == 'CYP') | (df['country'] == 'CZE') | \n",
    "         (df['country'] == 'DEU') | (df['country'] == 'GRC')]\n",
    "\n",
    "df3 = df[(df['country'] == 'HKG') | (df['country'] == 'IND') |\n",
    "         (df['country'] == 'IDN') | (df['country'] == 'IRN') | \n",
    "         (df['country'] == 'IRQ') | (df['country'] == 'JPN')]\n",
    "\n",
    "df4 = df[(df['country'] == 'JOR') | (df['country'] == 'KAZ') |\n",
    "         (df['country'] == 'KGZ') | (df['country'] == 'LBN') | \n",
    "         (df['country'] == 'MAC') | (df['country'] == 'MEX')]\n",
    "\n",
    "df5 = df[(df['country'] == 'MNG') | (df['country'] == 'NLD') |\n",
    "         (df['country'] == 'NZL') | (df['country'] == 'PAK') | \n",
    "         (df['country'] == 'ROU')]\n",
    "\n",
    "df6 = df[(df['country'] == 'RUS') | (df['country'] == 'SRB') |\n",
    "         (df['country'] == 'SGP') | (df['country'] == 'SVK') | \n",
    "         (df['country'] == 'KOR')]\n",
    "\n",
    "df7 = df[(df['country'] == 'TWN') | (df['country'] == 'TJK') |\n",
    "         (df['country'] == 'TUR') | (df['country'] == 'UKR')]\n",
    "\n",
    "df8 = df[(df['country'] == 'GBR') | (df['country'] == 'NIR') |\n",
    "         (df['country'] == 'USA') | (df['country'] == 'UZB') |\n",
    "         (df['country'] == 'VNM')]\n",
    "\n",
    "df9 = df[(df['country'] == 'BGD') | (df['country'] == 'BOL') |\n",
    "         (df['country'] == 'CHL') | (df['country'] == 'ECU') | \n",
    "         (df['country'] == 'EGY') | (df['country'] == 'ETH')]\n",
    "\n",
    "df10 = df[(df['country'] == 'GTM') | (df['country'] == 'KEN') |\n",
    "          (df['country'] == 'LBY') | (df['country'] == 'MYS') | \n",
    "          (df['country'] == 'MDV')]\n",
    "\n",
    "df11 = df[(df['country'] == 'MOR') | (df['country'] == 'MMR') |\n",
    "          (df['country'] == 'NIC') | (df['country'] == 'NGA') | \n",
    "          (df['country'] == 'PER') | (df['country'] == 'PHL')]\n",
    "\n",
    "df12 = df[(df['country'] == 'PRI') | (df['country'] == 'THA') |\n",
    "          (df['country'] == 'TUN') | (df['country'] == 'URY') | \n",
    "          (df['country'] == 'VEN') | (df['country'] == 'ZWE')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result) == len(df1) + len(df2) + len(df3) + len(df4) + len(df5) + len(df6) + len(df7) + len(df8) + len(df9) + len(df10) + len(df11) + len(df12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Смерджим этот датасет с ответами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethical_2_output = pd.read_csv('/Users/elizavetakuznecenkova/Library/CloudStorage/OneDrive-Personal/Документы/ВШЭ/Курсач/yandex_output/ethical_2_output.csv')\n",
    "ethical_3_output = pd.read_csv('/Users/elizavetakuznecenkova/Library/CloudStorage/OneDrive-Personal/Документы/ВШЭ/Курсач/yandex_output/ethical_3_output.csv')\n",
    "science_output = pd.read_csv('/Users/elizavetakuznecenkova/Library/CloudStorage/OneDrive-Personal/Документы/ВШЭ/Курсач/yandex_output/science_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = result\n",
    "df_final['full_ans_sci'] = science_output['full_ans']\n",
    "df_final['full_ans_eth_2'] = ethical_2_output['full_ans']\n",
    "df_final['full_ans_eth_3'] = ethical_3_output['full_ans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('/Users/elizavetakuznecenkova/Library/CloudStorage/OneDrive-Personal/Документы/ВШЭ/Курсач/df_for_analysis_yandex.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Добавим столбец с промтом и столбцы с инструкциями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>prompt</th>\n",
       "      <th>instr_ethical_1</th>\n",
       "      <th>instr_ethical_2</th>\n",
       "      <th>instr_ethical_3</th>\n",
       "      <th>instr_science</th>\n",
       "      <th>answer_format</th>\n",
       "      <th>answer_format_output</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Сейчас 2018 год.\\nВаш возраст - 60.\\nВы женщин...</td>\n",
       "      <td>Пожалуйста, ответьте по поводу каждого из след...</td>\n",
       "      <td>Пожалуйста, ответьте по поводу каждого из след...</td>\n",
       "      <td>Пожалуйста, ответьте по поводу каждого из след...</td>\n",
       "      <td>Пожалуйста, ответьте по каждому из следующих у...</td>\n",
       "      <td>На вход ты получаешь описание характеристик. Т...</td>\n",
       "      <td>В качестве ответа ты должен выдать последовате...</td>\n",
       "      <td>AND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Сейчас 2018 год.\\nВаш возраст - 47.\\nВы мужчин...</td>\n",
       "      <td>Пожалуйста, ответьте по поводу каждого из след...</td>\n",
       "      <td>Пожалуйста, ответьте по поводу каждого из след...</td>\n",
       "      <td>Пожалуйста, ответьте по поводу каждого из след...</td>\n",
       "      <td>Пожалуйста, ответьте по каждому из следующих у...</td>\n",
       "      <td>На вход ты получаешь описание характеристик. Т...</td>\n",
       "      <td>В качестве ответа ты должен выдать последовате...</td>\n",
       "      <td>AND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Сейчас 2018 год.\\nВаш возраст - 48.\\nВы мужчин...</td>\n",
       "      <td>Пожалуйста, ответьте по поводу каждого из след...</td>\n",
       "      <td>Пожалуйста, ответьте по поводу каждого из след...</td>\n",
       "      <td>Пожалуйста, ответьте по поводу каждого из след...</td>\n",
       "      <td>Пожалуйста, ответьте по каждому из следующих у...</td>\n",
       "      <td>На вход ты получаешь описание характеристик. Т...</td>\n",
       "      <td>В качестве ответа ты должен выдать последовате...</td>\n",
       "      <td>AND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Сейчас 2018 год.\\nВаш возраст - 62.\\nВы женщин...</td>\n",
       "      <td>Пожалуйста, ответьте по поводу каждого из след...</td>\n",
       "      <td>Пожалуйста, ответьте по поводу каждого из след...</td>\n",
       "      <td>Пожалуйста, ответьте по поводу каждого из след...</td>\n",
       "      <td>Пожалуйста, ответьте по каждому из следующих у...</td>\n",
       "      <td>На вход ты получаешь описание характеристик. Т...</td>\n",
       "      <td>В качестве ответа ты должен выдать последовате...</td>\n",
       "      <td>AND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Сейчас 2018 год.\\nВаш возраст - 49.\\nВы мужчин...</td>\n",
       "      <td>Пожалуйста, ответьте по поводу каждого из след...</td>\n",
       "      <td>Пожалуйста, ответьте по поводу каждого из след...</td>\n",
       "      <td>Пожалуйста, ответьте по поводу каждого из след...</td>\n",
       "      <td>Пожалуйста, ответьте по каждому из следующих у...</td>\n",
       "      <td>На вход ты получаешь описание характеристик. Т...</td>\n",
       "      <td>В качестве ответа ты должен выдать последовате...</td>\n",
       "      <td>AND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             prompt  \\\n",
       "0           0  Сейчас 2018 год.\\nВаш возраст - 60.\\nВы женщин...   \n",
       "1           1  Сейчас 2018 год.\\nВаш возраст - 47.\\nВы мужчин...   \n",
       "2           2  Сейчас 2018 год.\\nВаш возраст - 48.\\nВы мужчин...   \n",
       "3           3  Сейчас 2018 год.\\nВаш возраст - 62.\\nВы женщин...   \n",
       "4           4  Сейчас 2018 год.\\nВаш возраст - 49.\\nВы мужчин...   \n",
       "\n",
       "                                     instr_ethical_1  \\\n",
       "0  Пожалуйста, ответьте по поводу каждого из след...   \n",
       "1  Пожалуйста, ответьте по поводу каждого из след...   \n",
       "2  Пожалуйста, ответьте по поводу каждого из след...   \n",
       "3  Пожалуйста, ответьте по поводу каждого из след...   \n",
       "4  Пожалуйста, ответьте по поводу каждого из след...   \n",
       "\n",
       "                                     instr_ethical_2  \\\n",
       "0  Пожалуйста, ответьте по поводу каждого из след...   \n",
       "1  Пожалуйста, ответьте по поводу каждого из след...   \n",
       "2  Пожалуйста, ответьте по поводу каждого из след...   \n",
       "3  Пожалуйста, ответьте по поводу каждого из след...   \n",
       "4  Пожалуйста, ответьте по поводу каждого из след...   \n",
       "\n",
       "                                     instr_ethical_3  \\\n",
       "0  Пожалуйста, ответьте по поводу каждого из след...   \n",
       "1  Пожалуйста, ответьте по поводу каждого из след...   \n",
       "2  Пожалуйста, ответьте по поводу каждого из след...   \n",
       "3  Пожалуйста, ответьте по поводу каждого из след...   \n",
       "4  Пожалуйста, ответьте по поводу каждого из след...   \n",
       "\n",
       "                                       instr_science  \\\n",
       "0  Пожалуйста, ответьте по каждому из следующих у...   \n",
       "1  Пожалуйста, ответьте по каждому из следующих у...   \n",
       "2  Пожалуйста, ответьте по каждому из следующих у...   \n",
       "3  Пожалуйста, ответьте по каждому из следующих у...   \n",
       "4  Пожалуйста, ответьте по каждому из следующих у...   \n",
       "\n",
       "                                       answer_format  \\\n",
       "0  На вход ты получаешь описание характеристик. Т...   \n",
       "1  На вход ты получаешь описание характеристик. Т...   \n",
       "2  На вход ты получаешь описание характеристик. Т...   \n",
       "3  На вход ты получаешь описание характеристик. Т...   \n",
       "4  На вход ты получаешь описание характеристик. Т...   \n",
       "\n",
       "                                answer_format_output country  \n",
       "0  В качестве ответа ты должен выдать последовате...     AND  \n",
       "1  В качестве ответа ты должен выдать последовате...     AND  \n",
       "2  В качестве ответа ты должен выдать последовате...     AND  \n",
       "3  В качестве ответа ты должен выдать последовате...     AND  \n",
       "4  В качестве ответа ты должен выдать последовате...     AND  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/elizavetakuznecenkova/Library/CloudStorage/OneDrive-Personal/Документы/ВШЭ/Курсач/df_for_processing_rus/df_for_processing_rus.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97220"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97220/97220 [00:01<00:00, 85531.47it/s] \n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(df))):\n",
    "    if df.loc[i, 'country'] == 'MAR':\n",
    "        df.loc[i, 'country'] = 'MOR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[(df['country'] == 'AND') | (df['country'] == 'ARG') |\n",
    "         (df['country'] == 'ARM') | (df['country'] == 'BRA') | (df['country'] == 'CAN')]\n",
    "\n",
    "df2 = df[(df['country'] == 'CHN') | (df['country'] == 'COL') |\n",
    "         (df['country'] == 'CYP') | (df['country'] == 'CZE') | \n",
    "         (df['country'] == 'DEU') | (df['country'] == 'GRC')]\n",
    "\n",
    "df3 = df[(df['country'] == 'HKG') | (df['country'] == 'IND') |\n",
    "         (df['country'] == 'IDN') | (df['country'] == 'IRN') | \n",
    "         (df['country'] == 'IRQ') | (df['country'] == 'JPN')]\n",
    "\n",
    "df4 = df[(df['country'] == 'JOR') | (df['country'] == 'KAZ') |\n",
    "         (df['country'] == 'KGZ') | (df['country'] == 'LBN') | \n",
    "         (df['country'] == 'MAC') | (df['country'] == 'MEX')]\n",
    "\n",
    "df5 = df[(df['country'] == 'MNG') | (df['country'] == 'NLD') |\n",
    "         (df['country'] == 'NZL') | (df['country'] == 'PAK') | \n",
    "         (df['country'] == 'ROU')]\n",
    "\n",
    "df6 = df[(df['country'] == 'RUS') | (df['country'] == 'SRB') |\n",
    "         (df['country'] == 'SGP') | (df['country'] == 'SVK') | \n",
    "         (df['country'] == 'KOR')]\n",
    "\n",
    "df7 = df[(df['country'] == 'TWN') | (df['country'] == 'TJK') |\n",
    "         (df['country'] == 'TUR') | (df['country'] == 'UKR')]\n",
    "\n",
    "df8 = df[(df['country'] == 'GBR') | (df['country'] == 'NIR') |\n",
    "         (df['country'] == 'USA') | (df['country'] == 'UZB') |\n",
    "         (df['country'] == 'VNM')]\n",
    "\n",
    "df9 = df[(df['country'] == 'BGD') | (df['country'] == 'BOL') |\n",
    "         (df['country'] == 'CHL') | (df['country'] == 'ECU') | \n",
    "         (df['country'] == 'EGY') | (df['country'] == 'ETH')]\n",
    "\n",
    "df10 = df[(df['country'] == 'GTM') | (df['country'] == 'KEN') |\n",
    "          (df['country'] == 'LBY') | (df['country'] == 'MYS') | \n",
    "          (df['country'] == 'MDV')]\n",
    "\n",
    "df11 = df[(df['country'] == 'MOR') | (df['country'] == 'MMR') |\n",
    "          (df['country'] == 'NIC') | (df['country'] == 'NGA') | \n",
    "          (df['country'] == 'PER') | (df['country'] == 'PHL')]\n",
    "\n",
    "df12 = df[(df['country'] == 'PRI') | (df['country'] == 'THA') |\n",
    "          (df['country'] == 'TUN') | (df['country'] == 'URY') | \n",
    "          (df['country'] == 'VEN') | (df['country'] == 'ZWE')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['prompt'] = df['prompt']\n",
    "df_final['instr_science'] = df['instr_science']\n",
    "df_final['instr_ethical_2'] = df['instr_ethical_2']\n",
    "df_final['instr_ethical_3'] = df['instr_ethical_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разделим столбцы 'full_ans' по '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>version</th>\n",
       "      <th>doi</th>\n",
       "      <th>A_WAVE</th>\n",
       "      <th>A_YEAR</th>\n",
       "      <th>A_STUDY</th>\n",
       "      <th>B_COUNTRY</th>\n",
       "      <th>country</th>\n",
       "      <th>...</th>\n",
       "      <th>v2psplats</th>\n",
       "      <th>v2xnp_client</th>\n",
       "      <th>v2xps_party</th>\n",
       "      <th>full_ans_sci</th>\n",
       "      <th>full_ans_eth_2</th>\n",
       "      <th>full_ans_eth_3</th>\n",
       "      <th>prompt</th>\n",
       "      <th>instr_science</th>\n",
       "      <th>instr_ethical_2</th>\n",
       "      <th>instr_ethical_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6-0-0 (2024-04-30)</td>\n",
       "      <td>doi.org/10.14281/18241.24</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>AND</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>9\\n8\\n4\\n3\\n2</td>\n",
       "      <td>1\\n1\\n6\\n4\\n1\\n2\\n1</td>\n",
       "      <td>1\\n1\\n1\\n4\\n1\\n3</td>\n",
       "      <td>Сейчас 2018 год.\\nВаш возраст - 60.\\nВы женщин...</td>\n",
       "      <td>Пожалуйста, ответьте по каждому из следующих у...</td>\n",
       "      <td>Пожалуйста, ответьте по поводу каждого из след...</td>\n",
       "      <td>Пожалуйста, ответьте по поводу каждого из след...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 623 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Unnamed: 0.1  Unnamed: 0             version  \\\n",
       "0      0             0           0  6-0-0 (2024-04-30)   \n",
       "\n",
       "                         doi  A_WAVE  A_YEAR  A_STUDY  B_COUNTRY country  ...  \\\n",
       "0  doi.org/10.14281/18241.24       7    2018        2         20     AND  ...   \n",
       "\n",
       "   v2psplats v2xnp_client  v2xps_party   full_ans_sci       full_ans_eth_2  \\\n",
       "0     -999.0       -999.0       -999.0  9\\n8\\n4\\n3\\n2  1\\n1\\n6\\n4\\n1\\n2\\n1   \n",
       "\n",
       "     full_ans_eth_3                                             prompt  \\\n",
       "0  1\\n1\\n1\\n4\\n1\\n3  Сейчас 2018 год.\\nВаш возраст - 60.\\nВы женщин...   \n",
       "\n",
       "                                       instr_science  \\\n",
       "0  Пожалуйста, ответьте по каждому из следующих у...   \n",
       "\n",
       "                                     instr_ethical_2  \\\n",
       "0  Пожалуйста, ответьте по поводу каждого из след...   \n",
       "\n",
       "                                     instr_ethical_3  \n",
       "0  Пожалуйста, ответьте по поводу каждого из след...  \n",
       "\n",
       "[1 rows x 623 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_eth_2(row):\n",
    "    values = []\n",
    "    \n",
    "    if pd.notna(row['full_ans_eth_2']):\n",
    "        try:\n",
    "            parts = str(row['full_ans_eth_2']).split('\\n')\n",
    "            \n",
    "            for part in parts:\n",
    "                cleaned_part = part.strip()\n",
    "                \n",
    "                if not cleaned_part:\n",
    "                    continue\n",
    "                    \n",
    "                try:\n",
    "                    num = float(cleaned_part)\n",
    "                    values.append(num)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "            result = [np.nan] * 7\n",
    "            for i in range(min(len(values), 7)):\n",
    "                result[i] = values[i]\n",
    "\n",
    "            for i, col in enumerate(['Q183_yandex', 'Q184_yandex', 'Q185_yandex', 'Q186_yandex', 'Q187_yandex', 'Q188_yandex', 'Q189_yandex']):\n",
    "                row[col] = result[i]\n",
    "                \n",
    "        except Exception as error_in_data:\n",
    "            print(f\"Ошибка обработки строки {row.name}: {error_in_data}\")\n",
    "            for col in ['Q183_yandex', 'Q184_yandex', 'Q185_yandex', 'Q186_yandex', 'Q187_yandex', 'Q188_yandex', 'Q189_yandex']:\n",
    "                row[col] = np.nan\n",
    "                \n",
    "    else:\n",
    "        for col in ['Q183_yandex', 'Q184_yandex', 'Q185_yandex', 'Q186_yandex', 'Q187_yandex', 'Q188_yandex', 'Q189_yandex']:\n",
    "            row[col] = np.nan\n",
    "            \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_eth_3(row):\n",
    "    values = []\n",
    "    \n",
    "    if pd.notna(row['full_ans_eth_3']):\n",
    "        try:\n",
    "            parts = str(row['full_ans_eth_3']).split('\\n')\n",
    "            \n",
    "            for part in parts:\n",
    "                cleaned_part = part.strip()\n",
    "                \n",
    "                if not cleaned_part:\n",
    "                    continue\n",
    "                    \n",
    "                try:\n",
    "                    num = float(cleaned_part)\n",
    "                    values.append(num)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "            result = [np.nan] * 6\n",
    "            for i in range(min(len(values), 6)):\n",
    "                result[i] = values[i]\n",
    "\n",
    "            for i, col in enumerate(['Q190_yandex', 'Q191_yandex', 'Q192_yandex', 'Q193_yandex', 'Q194_yandex', 'Q195_yandex']):\n",
    "                row[col] = result[i]\n",
    "                \n",
    "        except Exception as error_in_data:\n",
    "            print(f\"Ошибка обработки строки {row.name}: {error_in_data}\")\n",
    "            for col in ['Q190_yandex', 'Q191_yandex', 'Q192_yandex', 'Q193_yandex', 'Q194_yandex', 'Q195_yandex']:\n",
    "                row[col] = np.nan\n",
    "                \n",
    "    else:\n",
    "        for col in ['Q190_yandex', 'Q191_yandex', 'Q192_yandex', 'Q193_yandex', 'Q194_yandex', 'Q195_yandex']:\n",
    "            row[col] = np.nan\n",
    "            \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_sci(row):\n",
    "    values = []\n",
    "    \n",
    "    if pd.notna(row['full_ans_sci']):\n",
    "        try:\n",
    "            parts = str(row['full_ans_sci']).split('\\n')\n",
    "            \n",
    "            for part in parts:\n",
    "                cleaned_part = part.strip()\n",
    "                \n",
    "                if not cleaned_part:\n",
    "                    continue\n",
    "                    \n",
    "                try:\n",
    "                    num = float(cleaned_part)\n",
    "                    values.append(num)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "            result = [np.nan] * 5\n",
    "            for i in range(min(len(values), 5)):\n",
    "                result[i] = values[i]\n",
    "\n",
    "            for i, col in enumerate(['Q158_yandex', 'Q159_yandex', 'Q160_yandex', 'Q161_yandex', 'Q162_yandex']):\n",
    "                row[col] = result[i]\n",
    "                \n",
    "        except Exception as error_in_data:\n",
    "            print(f\"Ошибка обработки строки {row.name}: {error_in_data}\")\n",
    "            for col in ['Q158_yandex', 'Q159_yandex', 'Q160_yandex', 'Q161_yandex', 'Q162_yandex']:\n",
    "                row[col] = np.nan\n",
    "                \n",
    "    else:\n",
    "        for col in ['Q158_yandex', 'Q159_yandex', 'Q160_yandex', 'Q161_yandex', 'Q162_yandex']:\n",
    "            row[col] = np.nan\n",
    "            \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.apply(clean_data_eth_2, axis = 1)\n",
    "df_final = df_final.apply(clean_data_eth_3, axis = 1)\n",
    "df_final = df_final.apply(clean_data_sci, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>version</th>\n",
       "      <th>doi</th>\n",
       "      <th>A_WAVE</th>\n",
       "      <th>A_YEAR</th>\n",
       "      <th>A_STUDY</th>\n",
       "      <th>B_COUNTRY</th>\n",
       "      <th>country</th>\n",
       "      <th>...</th>\n",
       "      <th>Q191_yandex</th>\n",
       "      <th>Q192_yandex</th>\n",
       "      <th>Q193_yandex</th>\n",
       "      <th>Q194_yandex</th>\n",
       "      <th>Q195_yandex</th>\n",
       "      <th>Q158_yandex</th>\n",
       "      <th>Q159_yandex</th>\n",
       "      <th>Q160_yandex</th>\n",
       "      <th>Q161_yandex</th>\n",
       "      <th>Q162_yandex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6-0-0 (2024-04-30)</td>\n",
       "      <td>doi.org/10.14281/18241.24</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>AND</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6-0-0 (2024-04-30)</td>\n",
       "      <td>doi.org/10.14281/18241.24</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>AND</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6-0-0 (2024-04-30)</td>\n",
       "      <td>doi.org/10.14281/18241.24</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>AND</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6-0-0 (2024-04-30)</td>\n",
       "      <td>doi.org/10.14281/18241.24</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>AND</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6-0-0 (2024-04-30)</td>\n",
       "      <td>doi.org/10.14281/18241.24</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>AND</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 641 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Unnamed: 0.1  Unnamed: 0             version  \\\n",
       "0      0             0           0  6-0-0 (2024-04-30)   \n",
       "1      1             1           1  6-0-0 (2024-04-30)   \n",
       "2      2             2           2  6-0-0 (2024-04-30)   \n",
       "3      3             3           3  6-0-0 (2024-04-30)   \n",
       "4      4             4           4  6-0-0 (2024-04-30)   \n",
       "\n",
       "                         doi  A_WAVE  A_YEAR  A_STUDY  B_COUNTRY country  ...  \\\n",
       "0  doi.org/10.14281/18241.24       7    2018        2         20     AND  ...   \n",
       "1  doi.org/10.14281/18241.24       7    2018        2         20     AND  ...   \n",
       "2  doi.org/10.14281/18241.24       7    2018        2         20     AND  ...   \n",
       "3  doi.org/10.14281/18241.24       7    2018        2         20     AND  ...   \n",
       "4  doi.org/10.14281/18241.24       7    2018        2         20     AND  ...   \n",
       "\n",
       "   Q191_yandex Q192_yandex  Q193_yandex  Q194_yandex  Q195_yandex  \\\n",
       "0          1.0         1.0          4.0          1.0          3.0   \n",
       "1          1.0         1.0          3.0          1.0          2.0   \n",
       "2          1.0         1.0          3.0          1.0          2.0   \n",
       "3          1.0         1.0          4.0          1.0          3.0   \n",
       "4          1.0         1.0          4.0          1.0          3.0   \n",
       "\n",
       "   Q158_yandex  Q159_yandex  Q160_yandex  Q161_yandex  Q162_yandex  \n",
       "0          9.0          8.0          4.0          3.0          2.0  \n",
       "1          9.0          8.0          3.0          4.0          2.0  \n",
       "2          8.0          9.0          3.0          4.0          2.0  \n",
       "3          8.0          9.0          3.0          4.0          3.0  \n",
       "4          9.0          8.0          3.0          4.0          3.0  \n",
       "\n",
       "[5 rows x 641 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('/Users/elizavetakuznecenkova/Library/CloudStorage/OneDrive-Personal/Документы/ВШЭ/Курсач/df_for_analysis_yandex.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
